# OCR/pii_main.py
import re
from datetime import datetime
from app.resources.dictionaries import NAMES, ORG_NAMES, RACES, STATUS, LOCATIONS, RELIGIONS

# === å»¶è¿ŸåŠ è½½æ¨¡å‹ ===
ner_pipeline = None
model_loaded = False

def load_model():
    """Lazy load the ML model only when needed"""
    global ner_pipeline, model_loaded
    if not model_loaded:
        try:
            print("ğŸ”„ Loading ML model for PII detection...")
            from transformers import TFAutoModelForTokenClassification, AutoTokenizer, pipeline

            model_name = "jplu/tf-xlm-r-ner-40-lang"
            tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=False)
            model = TFAutoModelForTokenClassification.from_pretrained(model_name)

            ner_pipeline = pipeline(
                task="ner",
                model=model,
                tokenizer=tokenizer,
                framework="tf",
                aggregation_strategy=None  # ç»†ç²’åº¦è¾“å‡º
            )
            model_loaded = True
            print("âœ… ML model loaded successfully")
        except Exception as e:
            print(f"âŒ Failed to load ML model: {e}")
            # Fallback to regex-only detection
            model_loaded = False

# === é€šç”¨å¿½ç•¥è¯ï¼ˆéæ•æ„Ÿï¼Œä¸éœ€åŠ å¯†ï¼‰===
IGNORE_WORDS = {
    "malaysia", "mykad", "identity", "card", "kad", "pengenalan",
    "warganegara", "lelaki", "perempuan", "bujang", "kawin",
    "lel", "per", "male", "female", "citizen", "not citizen"
}

# === å¢å¼ºçš„æ­£åˆ™æå–å™¨ ===
def extract_ic(text):
    """æå–é©¬æ¥è¥¿äºšèº«ä»½è¯å·ç """
    patterns = [
        r"\b\d{6}-\d{2}-\d{4}\b",  # æ ‡å‡†æ ¼å¼: 123456-78-9012
        r"\b\d{12}\b",             # æ— è¿å­—ç¬¦: 123456789012
        r"\b\d{6}\s\d{2}\s\d{4}\b" # ç©ºæ ¼åˆ†éš”: 123456 78 9012
    ]
    matches = []
    for pattern in patterns:
        matches.extend(re.findall(pattern, text))

    # éªŒè¯ICå·ç æ ¼å¼
    validated_matches = []
    for match in matches:
        clean_ic = re.sub(r'[-\s]', '', match)
        if len(clean_ic) == 12 and validate_malaysian_ic(clean_ic):
            validated_matches.append(match)

    return validated_matches

def extract_email(text):
    """æå–ç”µå­é‚®ä»¶åœ°å€"""
    pattern = r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b'
    return re.findall(pattern, text)

def extract_dob(text):
    """æå–å‡ºç”Ÿæ—¥æœŸ"""
    patterns = [
        r"\b\d{1,2}/\d{1,2}/\d{4}\b",      # DD/MM/YYYY or D/M/YYYY
        r"\b\d{1,2}-\d{1,2}-\d{4}\b",      # DD-MM-YYYY
        r"\b\d{4}-\d{1,2}-\d{1,2}\b",      # YYYY-MM-DD
        r"\b\d{1,2}\s+\w+\s+\d{4}\b",     # DD Month YYYY
    ]
    matches = []
    for pattern in patterns:
        matches.extend(re.findall(pattern, text))
    return matches

def extract_bank_account(text):
    """æå–é“¶è¡Œè´¦æˆ·å·ç """
    patterns = [
        r"\b\d{10,16}\b",                  # åŸºæœ¬è´¦æˆ·å·ç 
        r"\b\d{4}[-\s]?\d{4}[-\s]?\d{4,8}\b", # åˆ†æ®µæ ¼å¼
    ]
    matches = []
    for pattern in patterns:
        found = re.findall(pattern, text)
        # è¿‡æ»¤æ‰å¯èƒ½æ˜¯ç”µè¯å·ç æˆ–å…¶ä»–æ•°å­—çš„åŒ¹é…
        for match in found:
            clean_num = re.sub(r'[-\s]', '', match)
            if 10 <= len(clean_num) <= 16 and not is_phone_number(clean_num):
                matches.append(match)
    return matches

def extract_phone(text):
    """æå–ç”µè¯å·ç ï¼ˆé©¬æ¥è¥¿äºšæ ¼å¼ï¼‰"""
    patterns = [
        r'\+60\d{1,2}[-\s]?\d{7,8}',       # å›½é™…æ ¼å¼: +60123456789
        r'\b01\d[-\s]?\d{7,8}\b',          # æ‰‹æœº: 0123456789
        r'\b03[-\s]?\d{8}\b',              # å›ºè¯KL: 0312345678
        r'\b0[4-9]\d[-\s]?\d{7}\b',        # å…¶ä»–å·å›ºè¯
        r'\b\d{3}[-\s]?\d{7,8}\b',         # ç®€åŒ–æ ¼å¼
    ]
    matches = []
    for pattern in patterns:
        found = re.findall(pattern, text)
        for match in found:
            if validate_phone_number(match):
                matches.append(match)
    return matches

def extract_money(text):
    # æ›´ä¸¥æ ¼çš„é‡‘é¢åŒ¹é…
    patterns = [
        r'\b\d{1,3}(?:,\d{3})+(?:\.\d{1,2})?\b',  # e.g. 1,234.56 or 1,234
        r'\b\d{4,}(?:\.\d{1,2})?\b',              # e.g. 1234.5 or 1234.56
        r'\b\d{3}\.\d{1,2}\b'                     # e.g. 123.4 or 123.45
    ]
    matches = []
    for pattern in patterns:
        matches.extend(re.findall(pattern, text))
    unique_matches = list(set(matches))
    filtered_matches = []
    for match in unique_matches:
        try:
            num_value = float(match.replace(',', ''))
            # åªä¿ç•™åˆç†çš„é‡‘é¢èŒƒå›´ï¼ˆé¿å…åŒ¹é…æ—¥æœŸã€ç¼–å·ç­‰ï¼‰
            if 10 <= num_value <= 10000000:  # 10åˆ°1000ä¸‡ä¹‹é—´
                filtered_matches.append(match)
        except ValueError:
            continue  # è·³è¿‡æ— æ³•è½¬æ¢çš„å€¼
    return filtered_matches

def extract_gender(text):
    return re.findall(r'\b(LELAKI|PEREMPUAN|MALE|FEMALE)\b', text, re.I)

def extract_nationality(text):
    return re.findall(r'\b(WARGANEGARA|WARGA ASING|CITIZEN|NON-CITIZEN)\b', text, re.I)

def extract_passport(text):
    # åŒ¹é…æŠ¤ç…§å·ç æ ¼å¼ï¼š1ä¸ªå­—æ¯+7ä¸ªæ•°å­—ï¼Œæˆ–ç±»ä¼¼æ ¼å¼
    patterns = [
        r'\b[A-Z]\d{7,8}\b',      # H12345678 æˆ– H1234567
        r'\b[A-Z]{1,2}\d{6,7}\b', # HK1234567 æˆ– A1234567
        r'\b\d{8,9}[A-Z]\b'       # 12345678A (åå‘æ ¼å¼)
    ]
    
    matches = []
    for pattern in patterns:
        matches.extend(re.findall(pattern, text))
    
    return matches

def extract_credit_card(text):
    """æå–ä¿¡ç”¨å¡å·ç """
    patterns = [
        r"\b4\d{3}[\s-]?\d{4}[\s-]?\d{4}[\s-]?\d{4}\b",      # Visa
        r"\b5[1-5]\d{2}[\s-]?\d{4}[\s-]?\d{4}[\s-]?\d{4}\b", # Mastercard
        r"\b3[47]\d{2}[\s-]?\d{6}[\s-]?\d{5}\b",             # American Express
        r"\b6(?:011|5\d{2})[\s-]?\d{4}[\s-]?\d{4}[\s-]?\d{4}\b", # Discover
    ]
    matches = []
    for pattern in patterns:
        found = re.findall(pattern, text)
        for match in found:
            clean_cc = re.sub(r'[\s-]', '', match)
            if validate_credit_card(clean_cc):
                matches.append(match)
    return matches

def extract_malaysian_address(text):
    """æå–é©¬æ¥è¥¿äºšåœ°å€"""
    patterns = [
        r"\b\d+[A-Za-z]?,?\s+[A-Za-z\s]+,\s*\d{5}\s+[A-Za-z\s]+\b",  # æ ‡å‡†åœ°å€
        r"\b[A-Za-z\s]+,\s*\d{5}\s+[A-Za-z\s]+,\s*[A-Za-z\s]+\b",    # æ— é—¨ç‰Œå·
        r"\bNo\.?\s*\d+[A-Za-z]?,?\s+[A-Za-z\s]+,\s*\d{5}\b",        # No. å¼€å¤´
    ]
    matches = []
    for pattern in patterns:
        matches.extend(re.findall(pattern, text))
    return matches

def extract_vehicle_registration(text):
    """æå–è½¦ç‰Œå·ç """
    patterns = [
        r"\b[A-Z]{1,3}\s?\d{1,4}\s?[A-Z]?\b",  # é©¬æ¥è¥¿äºšè½¦ç‰Œ
        r"\b[A-Z]{2}\d{4}[A-Z]\b",             # æ–°æ ¼å¼
    ]
    matches = []
    for pattern in patterns:
        found = re.findall(pattern, text)
        for match in found:
            if validate_vehicle_plate(match):
                matches.append(match)
    return matches

# === éªŒè¯å‡½æ•° ===
def validate_malaysian_ic(ic_number: str) -> bool:
    if len(ic_number) != 12 or not ic_number.isdigit():
        return False

    try:
        # éªŒè¯å‡ºç”Ÿæ—¥æœŸæ˜¯å¦åˆæ³•
        year = int(ic_number[:2])
        month = int(ic_number[2:4])
        day = int(ic_number[4:6])
        full_year = 2000 + year if year <= 30 else 1900 + year
        datetime(full_year, month, day)
    except ValueError:
        return False

    return True

def validate_credit_card(cc_number):
    """ä½¿ç”¨Luhnç®—æ³•éªŒè¯ä¿¡ç”¨å¡å·ç """
    def luhn_checksum(card_num):
        def digits_of(n):
            return [int(d) for d in str(n)]
        digits = digits_of(card_num)
        odd_digits = digits[-1::-2]
        even_digits = digits[-2::-2]
        checksum = sum(odd_digits)
        for d in even_digits:
            checksum += sum(digits_of(d*2))
        return checksum % 10

    return luhn_checksum(cc_number) == 0

def validate_phone_number(phone):
    """éªŒè¯ç”µè¯å·ç æ ¼å¼"""
    clean_phone = re.sub(r'[\s-+]', '', phone)

    # é©¬æ¥è¥¿äºšæ‰‹æœºå·ç éªŒè¯
    if clean_phone.startswith('60'):
        clean_phone = clean_phone[2:]

    # æ‰‹æœºå·ç æ ¼å¼
    mobile_patterns = [
        r'^01[0-9]\d{7,8}$',  # æ‰‹æœº
        r'^03\d{8}$',         # å›ºè¯KL
        r'^0[4-9]\d{7,8}$',   # å…¶ä»–å·å›ºè¯
    ]

    for pattern in mobile_patterns:
        if re.match(pattern, clean_phone):
            return True

    return False

def validate_vehicle_plate(plate):
    """éªŒè¯è½¦ç‰Œå·ç æ ¼å¼"""
    clean_plate = re.sub(r'\s', '', plate.upper())

    # é©¬æ¥è¥¿äºšè½¦ç‰Œæ ¼å¼
    patterns = [
        r'^[A-Z]{1,3}\d{1,4}[A-Z]?$',  # æ ‡å‡†æ ¼å¼
        r'^[A-Z]{2}\d{4}[A-Z]$',       # æ–°æ ¼å¼
    ]

    for pattern in patterns:
        if re.match(pattern, clean_plate):
            return True

    return False

def is_phone_number(number_str):
    """æ£€æŸ¥æ•°å­—å­—ç¬¦ä¸²æ˜¯å¦å¯èƒ½æ˜¯ç”µè¯å·ç """
    clean_num = re.sub(r'[\s-]', '', number_str)
    return len(clean_num) in [10, 11, 12] and (clean_num.startswith('01') or clean_num.startswith('03'))

# === é©¬æ¥è¥¿äºšåœ°ç‚¹ç™½åå•ï¼ˆé˜²æ­¢è¯¯åˆå¹¶ï¼‰===
MALAYSIA_LOCATIONS = {
    "KUALA LUMPUR", "PETALING JAYA", "SELANGOR", "JOHOR", "JOHOR BAHRU",
    "PENANG", "GEORGETOWN", "ALOR SETAR", "KELANTAN", "TERENGGANU",
    "MELAKA", "KUCHING", "KOTA KINABALU", "LABUAN", "SABAH", "SARAWAK"
}

def extract_from_dictionaries(text, enabled_categories=None):
    """
    ä»å­—å…¸ä¸­æå–PIIï¼Œæ”¯æŒé€‰æ‹©æ€§ç±»åˆ«è¿‡æ»¤

    Args:
        text: è¦åˆ†æçš„æ–‡æœ¬
        enabled_categories: å¯ç”¨çš„é€‰æ‹©æ€§PIIç±»åˆ«åˆ—è¡¨

    Returns:
        list: [(label, value), ...] æ ¼å¼çš„ç»“æœ
    """
    if enabled_categories is None:
        enabled_categories = list(SELECTABLE_PII_CATEGORIES.keys())

    print(f"[DEBUG] å­—å…¸æå–ï¼Œå¯ç”¨ç±»åˆ«: {enabled_categories}")
    print("[DEBUG] åŸå§‹æ–‡æœ¬ï¼š", text[:200])  # åªæ˜¾ç¤ºå‰200å­—ç¬¦

    results = []
    text_lower = text.lower()

    # 1. å®Œæ•´åç§°åŒ¹é…ï¼ˆä¼˜å…ˆçº§æœ€é«˜ï¼‰
    if "NAMES" in enabled_categories:
        for name in NAMES:
            if name.lower() in text_lower:
                # ç¡®ä¿æ˜¯å®Œæ•´å•è¯åŒ¹é…ï¼Œä¸æ˜¯éƒ¨åˆ†åŒ¹é…
                pattern = r'\b' + re.escape(name.lower()) + r'\b'
                if re.search(pattern, text_lower):
                    results.append(("NAMES", name))
                    print(f"[DEBUG] æ‰¾åˆ°å®Œæ•´å§“å: {name}")

    # 2. å®Œæ•´ç»„ç»‡åç§°åŒ¹é…
    if "ORG_NAMES" in enabled_categories:
        for org in ORG_NAMES:
            if org.lower() in text_lower:
                pattern = r'\b' + re.escape(org.lower()) + r'\b'
                if re.search(pattern, text_lower):
                    results.append(("ORG_NAMES", org))
                    print(f"[DEBUG] æ‰¾åˆ°ç»„ç»‡åç§°: {org}")

    # 3. ç§æ—åŒ¹é…
    if "RACES" in enabled_categories:
        for race in RACES:
            if race.lower() in text_lower:
                pattern = r'\b' + re.escape(race.lower()) + r'\b'
                if re.search(pattern, text_lower):
                    results.append(("RACES", race))
                    print(f"[DEBUG] æ‰¾åˆ°ç§æ—: {race}")

    # 4. çŠ¶æ€åŒ¹é…
    if "STATUS" in enabled_categories:
        for status in STATUS:
            if status.lower() in text_lower:
                pattern = r'\b' + re.escape(status.lower()) + r'\b'
                if re.search(pattern, text_lower):
                    results.append(("STATUS", status))
                    print(f"[DEBUG] æ‰¾åˆ°çŠ¶æ€: {status}")

    # 5. åœ°ç‚¹åŒ¹é…
    if "LOCATIONS" in enabled_categories:
        for location in LOCATIONS:
            if location.lower() in text_lower:
                # åœ°ç‚¹å¯èƒ½åŒ…å«ç‰¹æ®Šå­—ç¬¦ï¼Œä½¿ç”¨æ›´å®½æ¾çš„åŒ¹é…
                if location.lower() in text_lower:
                    results.append(("LOCATIONS", location))
                    print(f"[DEBUG] æ‰¾åˆ°åœ°ç‚¹: {location}")

    # 6. å®—æ•™åŒ¹é…
    if "RELIGIONS" in enabled_categories:
        for religion in RELIGIONS:
            if religion.lower() in text_lower:
                pattern = r'\b' + re.escape(religion.lower()) + r'\b'
                if re.search(pattern, text_lower):
                    results.append(("RELIGIONS", religion))
                    print(f"[DEBUG] æ‰¾åˆ°å®—æ•™: {religion}")

    print(f"[DEBUG] å­—å…¸åŒ¹é…ç»“æœ: æ‰¾åˆ° {len(results)} ä¸ªPIIé¡¹")
    for label, value in results:
        print(f"[DEBUG]   - {label}: {value}")
    return results

# âœ… é€‰æ‹©æ€§PIIç±»åˆ«å®šä¹‰
SELECTABLE_PII_CATEGORIES = {
    "NAMES": "Personal names and identities",
    "RACES": "Ethnic and racial information",
    "ORG_NAMES": "Company and organization names",
    "STATUS": "Marital and social status",
    "LOCATIONS": "Geographic locations and addresses",
    "RELIGIONS": "Religious affiliations"
}

# âœ… éé€‰æ‹©æ€§PIIç±»åˆ«ï¼ˆå§‹ç»ˆé®ç½©ï¼‰
NON_SELECTABLE_PII_CATEGORIES = {
    "IC": "Malaysian IC numbers",
    "Email": "Email addresses",
    "DOB": "Date of birth",
    "Bank Account": "Bank account numbers",
    "Passport": "Passport numbers",
    "Phone": "Phone numbers",
    "Money": "Financial amounts",
    "Credit Card": "Credit card numbers",
    "Address": "Street addresses",
    "Vehicle Registration": "Vehicle registration numbers"
}

# âœ… ä¸»å‡½æ•°ï¼šæå–æ‰€æœ‰ PIIï¼ˆå¸¦é€‰æ‹©æ€§è¿‡æ»¤ï¼‰
def extract_all_pii(text, enabled_categories=None):
    """
    æå–PIIï¼Œæ”¯æŒé€‰æ‹©æ€§ç±»åˆ«è¿‡æ»¤

    Args:
        text: è¦åˆ†æçš„æ–‡æœ¬
        enabled_categories: å¯ç”¨çš„é€‰æ‹©æ€§PIIç±»åˆ«åˆ—è¡¨ï¼Œå¦‚ ["NAMES", "RACES"]
                          å¦‚æœä¸ºNoneï¼Œåˆ™å¯ç”¨æ‰€æœ‰ç±»åˆ«

    Returns:
        list: PIIå®ä½“åˆ—è¡¨ [(label, value), ...]
    """
    # å¦‚æœæœªæŒ‡å®šï¼Œé»˜è®¤å¯ç”¨æ‰€æœ‰é€‰æ‹©æ€§ç±»åˆ«
    if enabled_categories is None:
        enabled_categories = list(SELECTABLE_PII_CATEGORIES.keys())

    results = []

    # --- 1. NER æå–ï¼ˆç»†ç²’åº¦ï¼‰---
    try:
        # Load model if not already loaded
        if not model_loaded:
            load_model()

        if ner_pipeline is not None:
            ner_results = ner_pipeline(text)
        else:
            print("[WARN] NER model not available, using regex-only detection")
            ner_results = []
        tokens = []
        for ent in ner_results:
            word = ent["word"]
            entity = ent["entity"].replace("B-", "").replace("I-", "")
            # åˆ¤æ–­æ˜¯å¦æ˜¯æ–°è¯å¼€å§‹
            is_new_word = word.startswith("â–") or (not word.startswith("##") and not word.startswith("â–"))
            clean_word = word.replace("##", "").replace("â–", "")
            tokens.append({
                "word": clean_word,
                "entity": entity,
                "is_new_word": is_new_word
            })

        current_word = ""
        current_label = ""

        for tok in tokens:
            # å¦‚æœæ˜¯æ–°è¯ï¼Œç»“æŸå½“å‰è¯
            if current_label and tok["is_new_word"]:
                if current_word:
                    results.append((current_label, current_word))
                current_word = tok["word"]
                current_label = tok["entity"]
            # å¦‚æœæ˜¯å»¶ç»­ï¼ˆ## æˆ– â– å¼€å¤´ï¼‰ï¼Œä¸”å®ä½“ç±»å‹ç›¸åŒï¼Œåˆ™æ‹¼æ¥
            elif current_label == tok["entity"]:
                current_word += tok["word"]
            # ä¸åŒç±»å‹ï¼Œå…ˆç»“æŸæ—§çš„ï¼Œå†å¼€æ–°çš„
            else:
                if current_word:
                    results.append((current_label, current_word))
                current_word = tok["word"]
                current_label = tok["entity"]

        # ç»“æŸæœ€åä¸€ä¸ª
        if current_word:
            results.append((current_label, current_word))

    except Exception as e:
        print(f"[WARN] NER æå–å¤±è´¥: {e}")

    # --- 2. å¢å¼ºçš„æ­£åˆ™è§„åˆ™è¡¥å…… ---
    extractors = {
        "IC": extract_ic,
        "Email": extract_email,
        "DOB": extract_dob,
        "Bank Account": extract_bank_account,
        "Passport": extract_passport,
        "Phone": extract_phone,
        "Money": extract_money,
        "Gender": extract_gender,
        "Nationality": extract_nationality,
        "Credit Card": extract_credit_card,
        "Address": extract_malaysian_address,
        "Vehicle Registration": extract_vehicle_registration,
        "Name": lambda t: [],  # å¯æ‰©å±•ï¼šå§“åè§„åˆ™
    }

    print(f"[INFO] å¼€å§‹æ­£åˆ™æå–ï¼Œå…± {len(extractors)} ç§PIIç±»å‹")

    for label, func in extractors.items():
        matches = func(text)
        for match in matches:
            results.append((label, match.strip()))

    # --- 3. å­—å…¸åŒ¹é…è¡¥å……ï¼ˆé€‰æ‹©æ€§è¿‡æ»¤ï¼‰---
    dict_results = extract_from_dictionaries(text, enabled_categories)
    for label, value in dict_results:
        results.append((label, value))

    # --- 4. å»é‡ + è¿‡æ»¤éæ•æ„Ÿè¯ ---
    seen = set()
    filtered_results = []
    for label, value in results:
        clean_val = value.strip().lower()
        # è·³è¿‡ç©ºå€¼å’Œå¿½ç•¥è¯
        if not clean_val or clean_val in IGNORE_WORDS:
            continue
        if clean_val not in seen:
            seen.add(clean_val)
            filtered_results.append((label, value.strip()))  # ä¿ç•™åŸå§‹å¤§å°å†™

    return filtered_results